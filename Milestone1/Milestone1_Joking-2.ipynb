{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Milestone 1 : Regression - Predicting seismic collapse capacity",
   "metadata": {
    "cell_id": "00000-f267264e-662f-4e17-bbf2-752fb2aae285",
    "tags": [],
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Imports",
   "metadata": {
    "cell_id": "00001-713d9c02-d43d-43b0-875b-30423b81475d",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-c31ae156-e3c6-485f-978c-9ea340467ffa",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1839,
    "execution_start": 1621603593756,
    "source_hash": "e5a1cb28",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport metrics",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1.Data\n\n### 1.1 Import",
   "metadata": {
    "cell_id": "00003-27f8abf1-d4cd-4c44-b4f8-4cf2f95f8814",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-e158705f-0315-403b-99c0-cab4d707bd74",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1356,
    "execution_start": 1621603598304,
    "source_hash": "2e0b2325",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "df = {}\nfor t in ['train', 'test', 'val'] :\n    df[t] = pd.read_csv(f\"Data/{t}_set.csv\")\ndf['train'].head(5)",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.01</th>\n      <th>0.02</th>\n      <th>0.022</th>\n      <th>0.025</th>\n      <th>0.029</th>\n      <th>0.03</th>\n      <th>0.032</th>\n      <th>0.035</th>\n      <th>0.036</th>\n      <th>0.04</th>\n      <th>...</th>\n      <th>8.5</th>\n      <th>9.0</th>\n      <th>9.5</th>\n      <th>10.0</th>\n      <th>sa_avg</th>\n      <th>da5_75</th>\n      <th>da5_95</th>\n      <th>fiv3</th>\n      <th>sa_ratio</th>\n      <th>sat1_col</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.011075</td>\n      <td>0.011107</td>\n      <td>0.011132</td>\n      <td>0.011176</td>\n      <td>0.011274</td>\n      <td>0.011288</td>\n      <td>0.011341</td>\n      <td>0.011377</td>\n      <td>0.011422</td>\n      <td>0.011567</td>\n      <td>...</td>\n      <td>0.000247</td>\n      <td>0.000223</td>\n      <td>0.000206</td>\n      <td>0.000190</td>\n      <td>0.010809</td>\n      <td>14.484</td>\n      <td>21.416</td>\n      <td>2.881797</td>\n      <td>0.832237</td>\n      <td>0.78</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.155380</td>\n      <td>0.153050</td>\n      <td>0.154590</td>\n      <td>0.156281</td>\n      <td>0.161038</td>\n      <td>0.160171</td>\n      <td>0.159765</td>\n      <td>0.166164</td>\n      <td>0.173643</td>\n      <td>0.174708</td>\n      <td>...</td>\n      <td>0.002316</td>\n      <td>0.002225</td>\n      <td>0.002106</td>\n      <td>0.001998</td>\n      <td>0.031044</td>\n      <td>14.430</td>\n      <td>18.270</td>\n      <td>7.642059</td>\n      <td>0.961638</td>\n      <td>1.96</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.060774</td>\n      <td>0.060783</td>\n      <td>0.060790</td>\n      <td>0.060795</td>\n      <td>0.060799</td>\n      <td>0.060800</td>\n      <td>0.060804</td>\n      <td>0.060794</td>\n      <td>0.060793</td>\n      <td>0.060798</td>\n      <td>...</td>\n      <td>0.013225</td>\n      <td>0.012226</td>\n      <td>0.011904</td>\n      <td>0.011696</td>\n      <td>0.098425</td>\n      <td>16.700</td>\n      <td>35.105</td>\n      <td>42.218868</td>\n      <td>1.737888</td>\n      <td>1.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016016</td>\n      <td>0.016088</td>\n      <td>0.016106</td>\n      <td>0.016135</td>\n      <td>0.016198</td>\n      <td>0.016218</td>\n      <td>0.016263</td>\n      <td>0.016401</td>\n      <td>0.016445</td>\n      <td>0.016595</td>\n      <td>...</td>\n      <td>0.000192</td>\n      <td>0.000163</td>\n      <td>0.000139</td>\n      <td>0.000124</td>\n      <td>0.010169</td>\n      <td>7.320</td>\n      <td>17.370</td>\n      <td>2.599605</td>\n      <td>1.000551</td>\n      <td>1.97</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.030632</td>\n      <td>0.030699</td>\n      <td>0.030724</td>\n      <td>0.030738</td>\n      <td>0.030785</td>\n      <td>0.030809</td>\n      <td>0.030811</td>\n      <td>0.030818</td>\n      <td>0.030856</td>\n      <td>0.031014</td>\n      <td>...</td>\n      <td>0.004094</td>\n      <td>0.003350</td>\n      <td>0.002638</td>\n      <td>0.002224</td>\n      <td>0.037375</td>\n      <td>28.005</td>\n      <td>41.635</td>\n      <td>11.434507</td>\n      <td>1.371310</td>\n      <td>1.43</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 111 columns</p>\n</div>",
      "text/plain": "       0.01      0.02     0.022     0.025     0.029      0.03     0.032  \\\n0  0.011075  0.011107  0.011132  0.011176  0.011274  0.011288  0.011341   \n1  0.155380  0.153050  0.154590  0.156281  0.161038  0.160171  0.159765   \n2  0.060774  0.060783  0.060790  0.060795  0.060799  0.060800  0.060804   \n3  0.016016  0.016088  0.016106  0.016135  0.016198  0.016218  0.016263   \n4  0.030632  0.030699  0.030724  0.030738  0.030785  0.030809  0.030811   \n\n      0.035     0.036      0.04  ...       8.5       9.0       9.5      10.0  \\\n0  0.011377  0.011422  0.011567  ...  0.000247  0.000223  0.000206  0.000190   \n1  0.166164  0.173643  0.174708  ...  0.002316  0.002225  0.002106  0.001998   \n2  0.060794  0.060793  0.060798  ...  0.013225  0.012226  0.011904  0.011696   \n3  0.016401  0.016445  0.016595  ...  0.000192  0.000163  0.000139  0.000124   \n4  0.030818  0.030856  0.031014  ...  0.004094  0.003350  0.002638  0.002224   \n\n     sa_avg  da5_75  da5_95       fiv3  sa_ratio  sat1_col  \n0  0.010809  14.484  21.416   2.881797  0.832237      0.78  \n1  0.031044  14.430  18.270   7.642059  0.961638      1.96  \n2  0.098425  16.700  35.105  42.218868  1.737888      1.39  \n3  0.010169   7.320  17.370   2.599605  1.000551      1.97  \n4  0.037375  28.005  41.635  11.434507  1.371310      1.43  \n\n[5 rows x 111 columns]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Columns options :",
   "metadata": {
    "cell_id": "00005-95d96068-970d-45a3-bd26-778c0ba34f0e",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-46bb2e0a-fb51-4271-acee-98c0744668a1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1621603600462,
    "source_hash": "a451fd04",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "X_col = {}\ny_col = ['sat1_col']\n#Option 1 : All\nX_col[\"All\"] = df['test'].columns.to_numpy()\n#Option 2 : Reduce to last columns (no sa(T), only the other columns. sa_ratio and sa_avg is there to convey the sa information)\nX_col[\"Reduced\"] = ['1.3','sa_avg','da5_75', 'da5_95', 'fiv3', 'sa_ratio']\n#Option 3 : Best 15 cols (section 7.)\nX_col['Best_15'] = ['sa_avg', 'fiv3', 'da5_95', '0.06', '0.1', 'max_period', 'da5_75', '1.5', '0.07'\n, '0.34', '0.32', '0.03', '0.4', '0.13', '9.0']",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Data Expansion : Max Period",
   "metadata": {
    "cell_id": "00007-48bb6665-dafc-458b-a6f5-3ba842ae56d9",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-385e24a6-b7b1-40cf-884c-3b46e6a40a0a",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 110,
    "execution_start": 1621603606346,
    "source_hash": "9213e326",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "for t in ['train', 'test', 'val'] :\n    df[t]['max_period'] = df[t][df['test'].columns.difference(X_col[\"Reduced\"]+[\"max_period\"])].idxmax(axis=\"columns\").astype(\"float\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-0ba978be-4422-4ba1-a8a0-ec51136e7245",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1621603606704,
    "source_hash": "4c85566d",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "df['val']['sat1_col']",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "0       1.65\n1       1.29\n2       1.40\n3       1.90\n4       2.34\n        ... \n1495    1.00\n1496    1.00\n1497    1.26\n1498    1.30\n1499    1.54\nName: sat1_col, Length: 1500, dtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-5edb3cc6-989a-4694-9548-02c9525196da",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1621603616526,
    "source_hash": "7b5b3102",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "#Option 3 and 3.1 : Add max_period\nX_col[\"Red_max_period\"] = ['sa_avg','da5_75', 'da5_95', 'fiv3', 'sa_ratio', 'max_period']\nX_col[\"All_max_period\"] = df['test'].columns.to_numpy()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Choice of parameters",
   "metadata": {
    "cell_id": "00011-96675cb8-aa90-4e2b-a6f3-cb0cbe0069a5",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1621261521690,
    "source_hash": "d081a91a",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-ac352028-eb60-4799-aff8-963507677c7d",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1621602502819,
    "source_hash": "412fe221",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "#Choix :\ncolumns = \"All_max_period\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-c879c1cb-fe7a-4597-951c-b6020260a064",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1621602503320,
    "source_hash": "5a42f4a8",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "X_train = df['train'][X_col[columns]].to_numpy()\ny_train = df['train'][y_col].to_numpy()\n\nX_val = df['val'][X_col[columns]].to_numpy()\ny_val = df['val'][y_col].to_numpy()\n\nX_test = df['test'][X_col[columns]].to_numpy()\n\ncols_map = np.array(X_col[columns])\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)\nprint(cols_map)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(12646, 111)\n(3000, 111)\n(1500, 111)\n['0.01' '0.02' '0.022' '0.025' '0.029' '0.03' '0.032' '0.035' '0.036'\n '0.04' '0.042' '0.044' '0.045' '0.046' '0.048' '0.05' '0.055' '0.06'\n '0.065' '0.067' '0.07' '0.075' '0.08' '0.085' '0.09' '0.095' '0.1' '0.11'\n '0.12' '0.13' '0.133' '0.14' '0.15' '0.16' '0.17' '0.18' '0.19' '0.2'\n '0.22' '0.24' '0.25' '0.26' '0.28' '0.29' '0.3' '0.32' '0.34' '0.35'\n '0.36' '0.38' '0.4' '0.42' '0.44' '0.45' '0.46' '0.48' '0.5' '0.55' '0.6'\n '0.65' '0.667' '0.7' '0.75' '0.8' '0.85' '0.9' '0.95' '1.0' '1.1' '1.2'\n '1.3' '1.4' '1.5' '1.6' '1.7' '1.8' '1.9' '2.0' '2.2' '2.4' '2.5' '2.6'\n '2.8' '3.0' '3.2' '3.4' '3.5' '3.6' '3.8' '4.0' '4.2' '4.4' '4.6' '4.8'\n '5.0' '5.5' '6.0' '6.5' '7.0' '7.5' '8.0' '8.5' '9.0' '9.5' '10.0'\n 'sa_avg' 'da5_75' 'da5_95' 'fiv3' 'sa_ratio' 'max_period']\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 1.2 Normalisation",
   "metadata": {
    "cell_id": "00014-0a5166ba-2a34-4ba4-898b-8c197834fb79",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1619791917697,
    "source_hash": "57ed6dd2",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00015-c4a37308-7d70-49da-9ab8-02eba00c4285",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1621602506213,
    "source_hash": "bce64eb8",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "mean = X_train.mean(axis=0)\nstd = X_train.std(axis=0)\n\ndef Normalise(X):\n    return (X-mean)/std\n\nX_train = Normalise(X_train)\nX_val = Normalise(X_val)\nX_test = Normalise(X_test)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 1.3 Import en Pytorch\n\nhttps://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader",
   "metadata": {
    "cell_id": "00016-091547ea-af9a-48ae-a848-48d25cfce56f",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-05b575f4-6e4c-446c-939e-14ad2780e866",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1621602507900,
    "source_hash": "4b7c1b7e",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "def convert_to_dataloader(x, y=None, batch_size = 10):\n    tensor_x = torch.Tensor(x)\n    try:\n        if y == None:\n            dataset = torch.utils.data.TensorDataset(tensor_x)\n    except:\n        tensor_y = torch.Tensor(y)\n        dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y)\n    return torch.utils.data.DataLoader(dataset, batch_size = batch_size)\n\ndataload_train = convert_to_dataloader(X_train, y_train)\ndataload_val = convert_to_dataloader(X_val, y_val)\ndataload_test = convert_to_dataloader(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Models",
   "metadata": {
    "cell_id": "00018-be32b155-80ab-4cae-9a1c-a151c1113419",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1619796408523,
    "source_hash": "b623e53d",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### 2.1 OneLayerNet",
   "metadata": {
    "cell_id": "00019-42fe4a47-a86d-4dff-ade3-1430c0da0228",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00020-05e09a36-f3a6-4d3d-83a4-3d9117b9f5c4",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1621602510544,
    "source_hash": "6fd242ec",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "class OneLayerNet(nn.Module):\n    \"\"\"1-Layer linear\"\"\"\n    \n    def __init__(self, cols):\n        super().__init__()\n        self.fc1 = nn.Linear(cols, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.flatten(start_dim=1)\n        x = self.fc1(x)\n        return x\n  \n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        y = self.forward(x)\n        return y\n\none_layer_net = OneLayerNet(X_train.shape[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.2 ThreeLayerNet",
   "metadata": {
    "cell_id": "00021-a41c7e1e-a7a5-41fd-a92b-f47e284aaad6",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00022-afd04e2d-71b7-4c59-aaa6-4d840f287760",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1621602512307,
    "source_hash": "f3646c25",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "class ThreeLayerNet(nn.Module):\n    \"\"\"3-Layer linear+RELU\"\"\"\n    \n    def __init__(self, cols):\n        super().__init__()\n        self.fc1 = nn.Linear(cols, cols//2)\n        self.fc2 = nn.Linear(cols//2, cols//4)\n        self.fc3 = nn.Linear(cols//4, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.flatten(start_dim=1)\n        x = self.fc1(x)\n        x = self.fc2(F.relu(x))\n        x = self.fc3(F.relu(x))\n        return x\n  \n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        y = self.forward(x)\n        return y\n\nthree_layer_net = ThreeLayerNet(X_train.shape[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.3 FourLayerNet",
   "metadata": {
    "cell_id": "00023-736470cd-62da-4363-bfc1-cebb253e118d",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00024-5c488e7c-0a66-494c-a2b9-fc3dd0289e61",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1621602513929,
    "source_hash": "873d88d6",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "class FourLayerNet(nn.Module):\n    \"\"\"4-Layer linear+RELU + Non-linear\"\"\"\n    \n    def __init__(self, cols):\n        super().__init__()\n        self.fc1 = nn.Linear(cols, cols//2)\n        self.fc2 = nn.Linear(cols//2, cols//4)\n        self.fc3 = nn.Linear(2*(cols//4), cols//4)\n        self.fc4 = nn.Linear(cols//4, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.flatten(start_dim=1)\n        x = self.fc1(x)\n        x = self.fc2(F.relu(x))\n        x2 = x**2\n        x = torch.stack([x, x2], dim=2).flatten(start_dim=1) # Adding x^2 terms\n        x = self.fc3(F.relu(x))\n        x = self.fc4(F.relu(x))\n        return x\n\n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        y = self.forward(x)\n        return y\n\nfour_layer_net = FourLayerNet(X_train.shape[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.4 NonLinearNet",
   "metadata": {
    "cell_id": "00025-2048d229-ad30-4397-87e8-537fa892475e",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Very Bad Result : Loss goes in dent de scie",
   "metadata": {
    "cell_id": "00026-6bd36017-5474-45c7-b1d9-906508dbd847",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "allow_embed": false,
    "cell_id": "00027-76262b52-0155-4488-82e8-bf0e1feaab71",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1621602515514,
    "source_hash": "bc8478ae",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "class NonLinearNet(nn.Module):\n    \"\"\"Non-linear (first)\"\"\"\n    \n    def __init__(self, cols):\n        super().__init__()\n        self.fc1 = nn.Linear(cols, cols//4)\n        self.fc2 = nn.Linear(4*(cols//4), cols//2)\n        self.fc3 = nn.Linear(cols//2, cols//8)\n        self.fc4 = nn.Linear(cols//8, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.flatten(start_dim=1)\n        x = F.relu(self.fc1(x))\n        x = torch.stack([x, x**2, torch.log(x+1e-3), torch.exp(x)], dim=2).flatten(start_dim=1) # Adding x^2, log, exp terms\n        x = self.fc2(F.gelu(x))\n        x = self.fc3(F.relu(x))\n        x = self.fc4(F.relu(x))\n        return x\n\n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        y = self.forward(x)\n        return y\n\nnon_linear_net = NonLinearNet(X_train.shape[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "allow_embed": false,
    "cell_id": "00028-675f9a6b-c30e-4488-a3ff-c75c6a08a523",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1621602517067,
    "source_hash": "6760073a",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "class NonLinearNet2(nn.Module):\n    \"\"\"Non-linear (second)\"\"\"\n    \n    def __init__(self, cols):\n        super().__init__()\n        self.fc1 = nn.Linear(3*cols, cols)\n        self.fc2 = nn.Linear(cols, cols//2)\n        self.fc3 = nn.Linear(cols//2, cols//4)\n        self.fc4 = nn.Linear(cols//4, 1)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.flatten(start_dim=1)\n        x2 = torch.hstack((x[:,1:]*x[:,:-1], (x[:,1]*x[:,-1]).view(-1,1))) #xy terms\n        x = torch.hstack([x, x**2, x2]) #Adding x^2, xy terms\n        x = self.fc1(x)\n        x = self.fc2(F.gelu(x))\n        x = self.fc3(F.relu(x))\n        x = self.fc4(F.relu(x))\n        return x\n\n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        y = self.forward(x)\n        return y\n\nnon_linear_net2 = NonLinearNet2(X_train.shape[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Training\n\n### 3.1 Loss function",
   "metadata": {
    "cell_id": "00029-21a1df43-a957-4131-8390-3ca902d807ca",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00030-424daade-2cdc-4242-a820-ee57d1fa41c8",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1621602320640,
    "source_hash": "9f49d7be",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "loss_fn = nn.MSELoss(reduction=\"mean\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.2 Training",
   "metadata": {
    "cell_id": "00031-013aa92f-04d2-45c3-bb7c-9ada84ec3f88",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00032-20934eaf-3c64-47c3-86ed-2918e69105a9",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1621602522618,
    "source_hash": "de2244f7",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "def train(model: torch.nn.Module, train_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, epochs: int):\n    \n    # Initialize metrics for loss and accuracy\n    #loss_metric = metrics.LossMetric()\n    \n    # Sets the module in training mode (doesn't have any effect here, but good habit to take)\n    model.train()\n    \n    for epoch in range(1, epochs + 1):\n        losses = []\n        # Progress bar set-up\n        #pbar = tqdm(total=len(train_loader), leave=True)\n        #pbar.set_description(f\"Epoch {epoch}\")\n        \n        # Iterate through data\n        for data, target in train_loader:\n            \n            ### START CODE HERE ###\n            \n            # Zero-out the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            out = model(data)\n            \n            # Compute loss\n            loss = loss_fn(out, target)\n            \n            # Backward pass\n            loss.backward()\n            \n            # Optimizer step\n            optimizer.step()\n            \n            ### END CODE HERE ###\n            \n            # Update metrics & progress bar\n            #loss_metric.update(loss.item(), data.shape[0])\n            #pbar.update()\n            losses.append(loss.item())\n            \n        # End of epoch, show loss and acc\n        #pbar.set_postfix_str(f\"Train loss: {loss_metric.compute():.3f} | Train acc: {acc_metric.compute() * 100:.2f}%\")\n        #print(f\"Train loss: {loss_metric.compute():.3f}\")\n        #loss_metric.reset()\n\n        #print(epoch, np.mean(losses))\n    return np.mean(losses)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00033-60b37c54-45b7-475c-9e67-8bc9332d36ef",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00033-246915aa-c943-4ca3-a0fb-e3786ad7af63",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 379236,
    "execution_start": 1621602527096,
    "source_hash": "684a01f8",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "models = [three_layer_net, four_layer_net]\nloss_dict = {}\n\nfor model in models:\n    for name, module in model.named_children():\n        module.reset_parameters()\n        \nfor model in models:\n    #opti_Adadelta = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n    #opti_Adagrad = torch.optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n    opti_Adam = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n    opti_AdamW = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n    #opti_SparseAdam = torch.optim.SparseAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n    opti_Adamax = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n    #opti_ASGD = torch.optim.ASGD(model.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n    #opti_LBFGS = torch.optim.LBFGS(model.parameters(), lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n    #opti_RMSprop = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n    #opti_Rprop = torch.optim.Rprop(model.parameters(), lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n    opti_SGD = torch.optim.SGD(model.parameters(), lr=.001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n    #optimizers = [opti_Adadelta, opti_Adagrad, opti_Adam, opti_AdamW, opti_Adamax, opti_ASGD, opti_RMSprop, opti_Rprop, opti_SGD]\n    optimizers = [opti_Adam, opti_AdamW, opti_Adamax, opti_ASGD, opti_SGD]\n    for optimizer in optimizers:\n        loss_train = train(model, dataload_train, loss_fn, optimizer, epochs=200)\n        name = str(optimizer).split()[0] + str(model).split()[0]\n        loss_dict[name] = loss_train\n        print(name, \"trained , train loss is\", loss_train)\n        \n        for name, module in model.named_children():\n            module.reset_parameters()\n        \nprint(loss_dict)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AdadeltaThreeLayerNet( trained , train loss is 0.15078850221919565\nAdagradThreeLayerNet( trained , train loss is 0.1383068047625863\nAdamThreeLayerNet( trained , train loss is 0.10467863466237255\nAdamWThreeLayerNet( trained , train loss is 0.12521074468512897\nAdamaxThreeLayerNet( trained , train loss is 0.10954993677145172\nASGDThreeLayerNet( trained , train loss is 0.11723588932997625\nRMSpropThreeLayerNet( trained , train loss is 0.1732360282588912\nRpropThreeLayerNet( trained , train loss is 0.2019813600515306\nSGDThreeLayerNet( trained , train loss is 0.14246537910236906\nAdadeltaFourLayerNet( trained , train loss is 0.15628147209836207\nAdagradFourLayerNet( trained , train loss is 0.13729510836509376\nAdamFourLayerNet( trained , train loss is 0.11156777737757906\nAdamWFourLayerNet( trained , train loss is 0.12283716428833516\nAdamaxFourLayerNet( trained , train loss is 0.10380421756240336\nASGDFourLayerNet( trained , train loss is nan\nRMSpropFourLayerNet( trained , train loss is 0.3134871259950131\nRpropFourLayerNet( trained , train loss is 0.23297664456054745\nSGDFourLayerNet( trained , train loss is 0.14174696448233287\nAdadeltaNonLinearNet( trained , train loss is nan\nAdagradNonLinearNet( trained , train loss is 119.95646359553274\nAdamNonLinearNet( trained , train loss is nan\nAdamWNonLinearNet( trained , train loss is nan\nAdamaxNonLinearNet( trained , train loss is 0.11503885957475\nASGDNonLinearNet( trained , train loss is nan\nRMSpropNonLinearNet( trained , train loss is nan\nRpropNonLinearNet( trained , train loss is 2.677936228757901e+23\nSGDNonLinearNet( trained , train loss is nan\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'hstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4953b134ac1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopti_Adadelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_Adagrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_Adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_AdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_Adamax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_ASGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_RMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_Rprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_SGD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataload_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9100d93618a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/introml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f2349de13765>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#xy terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Adding x^2, xy terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'hstack'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Test on validation",
   "metadata": {
    "cell_id": "00034-63bca855-3ccd-42a6-9cb3-167356b6514b",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00035-9a945eb5-7cd5-4244-8ea1-0b912d8858b0",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1621438109806,
    "source_hash": "8d2dad3b",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "def test(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader):\n\n    model.eval()\n    losses = []\n    \n    with torch.no_grad():\n        for data, target in dataloader:\n            # Forward pass\n            out = model(data)\n            \n            losses.append(loss_fn(out,target).item())\n        ### END CODE HERE ###\n            \n    return np.mean(losses)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00036-20608696-d17e-4abf-a076-ee8f2f874422",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 65,
    "execution_start": 1621442063151,
    "source_hash": "3ccfb84e",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "model = FourLayerNet(X_train.shape[1])\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=500)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss)      \n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Tested out two models with different optimizers",
   "metadata": {
    "cell_id": "00038-88dccdf4-e3a2-494d-8081-ad2dbd5d48cb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00039-f2b719f6-d9d1-4b4b-8c17-e901cfe1f901",
    "deepnote_cell_type": "code"
   },
   "source": "model = FourLayerNet(X_train.shape[1])\n\nopti_Adam = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\nopti_AdamW = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\nopti_Adamax = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\nopti_ASGD = torch.optim.ASGD(model.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\nopti_SGD = torch.optim.SGD(model.parameters(), lr=.001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\noptimizers = [opti_Adam, opti_AdamW, opti_Adamax, opti_ASGD, opti_SGD]\n\nfor optimizer in optimizers:\n    loss_train = train(model, dataload_train, loss_fn, optimizer, epochs=500)\n    name = str(optimizer).split()[0] + str(model).split()[0]\n    print(name, \"trained , train loss is\", loss_train)      \n    val_loss = test(model, dataload_val)\n    print(name, \"trained , validation loss is\", val_loss)      \n\n        \n    for name, module in model.named_children():\n            module.reset_parameters()\n        \n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00040-3c4d69c7-8b62-4ca4-b9a8-8dbaf830c0c8",
    "deepnote_cell_type": "code"
   },
   "source": "model = ThreeLayerNet(X_train.shape[1])\n\n#opti_Adam = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\nopti_AdamW = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n#opti_Adamax = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\nopti_ASGD = torch.optim.ASGD(model.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\nopti_SGD = torch.optim.SGD(model.parameters(), lr=.001, momentum=0, dampening=0, weight_decay=0, nesterov=False)\noptimizers = [ opti_AdamW, opti_ASGD, opti_SGD]\n\nfor optimizer in optimizers:\n    loss_train = train(model, dataload_train, loss_fn, optimizer, epochs=500)\n    name = str(optimizer).split()[0] + str(model).split()[0]\n    print(name, \"trained , train loss is\", loss_train)      \n    val_loss = test(model, dataload_val)\n    print(name, \"trained , validation loss is\", val_loss)      \n\n        \n    for name, module in model.named_children():\n            module.reset_parameters()\n        \n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Trying out best optimizers with model",
   "metadata": {
    "cell_id": "00041-3a3ace64-8f85-407a-92f8-28549230b4f5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Four Layer Network",
   "metadata": {
    "cell_id": "00042-bb940bde-5321-43ef-bd7b-609947ec0533",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00043-2a185b61-2b0e-4f69-a5cb-c3b8cfc6232a",
    "deepnote_cell_type": "code"
   },
   "source": "model = FourLayerNet(X_train.shape[1])\noptimizer = opti_AdamW = torch.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.99, 0.9999), eps=1e-07, weight_decay=0.001, amsgrad=False)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=800)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss) \n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AdamWFourLayerNet( trained , train loss is 0.08069558408582517\nAdamWFourLayerNet( trained , validation loss is 0.19486766502261163\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00044-1e20c3fe-484e-4cf2-8942-5357c921642d",
    "deepnote_cell_type": "code"
   },
   "source": "model = FourLayerNet(X_train.shape[1])\noptimizer =  torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0, dampening=0, weight_decay=0.001, nesterov=False)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=900)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss)      ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "model = FourLayerNet(X_train.shape[1])\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-09, weight_decay=0.0001)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=500)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss)",
   "metadata": {
    "cell_id": "00045-937e72eb-b405-4433-83b3-634601d156c1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00046-b2380eaf-2dbb-48bc-ac32-a13e7b53fbaa",
    "deepnote_cell_type": "code"
   },
   "source": "model = FourLayerNet(X_train.shape[1])\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=800)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AdamFourLayerNet( trained , train loss is 0.08266068142047336\nAdamFourLayerNet( trained , validation loss is 0.23321783877288302\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Non Linear Network",
   "metadata": {
    "cell_id": "00047-2a9da025-8c68-4f20-978f-5c7845a324e2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00048-29a4cd48-07b7-4fd0-b093-d59f5c684cc0",
    "deepnote_cell_type": "code"
   },
   "source": "model = NonLinearNet(X_train.shape[1])\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\nloss_train = train(model, dataload_train, loss_fn, optimizer, epochs=500)\nname = str(optimizer).split()[0] + str(model).split()[0]\nprint(name, \"trained , train loss is\", loss_train)      \nval_loss = test(model, dataload_val)\nprint(name, \"trained , validation loss is\", val_loss) ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AdamaxNonLinearNet( trained , train loss is 0.09256233597108027\nAdamaxNonLinearNet( trained , validation loss is 1.5539655258134006\n"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Export Results",
   "metadata": {
    "cell_id": "00037-0319d1f5-b680-4190-a332-54638b846d0c",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00038-f9a48487-683d-4a51-b8a2-a187c81e5261",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 260,
    "execution_start": 1621342125220,
    "source_hash": "f5a6b76b",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00039-f94f1461-fc94-4fe5-b3de-33244276ad5a",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 48,
    "execution_start": 1621439114497,
    "source_hash": "18b0f9ff",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "model_name = model.__repr__().split('(')[0]\n\ny_test = model(torch.Tensor(X_test))\ndf_out = pd.DataFrame(y_test.detach().numpy())\ndf_out.columns = ['sat1_col']\ndf_out.to_csv(f\"submission_Joking_{model_name}.csv\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6. Saving results for future purpose\n",
   "metadata": {
    "cell_id": "00040-27bf4060-3c9a-4608-884a-39c6bb3390ba",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00041-47a6c9e4-0eec-47e4-b128-d191917453a3",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1621442072883,
    "source_hash": "6f2e75f3",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "f= open(\"history.txt\", \"a+\")\nf.write(f\"\"\"\n------------\n\n{model}\n\nColumns : {columns}\nVAL LOSS : {val_loss}\"\"\")\nf.close()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Exploring weights : identifying which cols are used",
   "metadata": {
    "cell_id": "00042-4a5b74c1-95ed-44d1-9590-bbd378af2871",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00043-4fda7d25-2749-4cfa-b808-3bbd66277bfc",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1621603164314,
    "source_hash": "51989476",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "weightss = torch.Tensor(list(one_layer_net.parameters())[0]).detach().numpy().reshape((-1))\nprint(weightss)\nprint(cols_map[np.argsort(np.abs(weightss))])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00044-f1645a1c-50c7-4222-b6e3-208a9bb03cc0",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=493ee647-e437-4c81-80f8-96d4eefd9c39' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "478d7394-2dd1-4775-bb43-831163bcae20",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 }
}
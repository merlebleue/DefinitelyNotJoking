{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "bf27883f24a5f59ded61cdabdf5884d91cb393caeb24728749abd210759b939b"
      }
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "statistical-rogers"
      },
      "source": [
        "# Example training notebook"
      ],
      "id": "statistical-rogers"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crucial-anime"
      },
      "source": [
        "This notebook shows how to train a basic model on fixed scale images of the AIST Building Change Detection dataset. Feel free to modify it as you wish."
      ],
      "id": "crucial-anime"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "strange-commander"
      },
      "source": [
        "####  For Google Colab\n",
        "These cells are used to setup the repository, required packages and dataset in Colab."
      ],
      "id": "strange-commander"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovely-paradise"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    \n",
        "if IN_COLAB:\n",
        "    # Clone the entire repo to access the files\n",
        "    !git clone -l -s https://github.com/vita-epfl/introML-2021.git cloned-repo\n",
        "    # Go to the project directory\n",
        "    %cd cloned-repo/project/\n",
        "    # Install requirements\n",
        "    !pip install -r requirements.txt"
      ],
      "id": "lovely-paradise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stretch-second"
      },
      "source": [
        "# This cell downloads the dataset if you're using Colab\n",
        "# If the dataset is already downloaded, avoid running it again after restarting the kernel\n",
        "if IN_COLAB:\n",
        "    !pip install gdown\n",
        "    !gdown https://drive.google.com/uc?id=1otKxIvEP77Cap9VmUkujMrAMo4K8_F1c\n",
        "    !unzip -q patch-pairs.zip -d data/"
      ],
      "id": "stretch-second",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conservative-kelly"
      },
      "source": [
        "### Imports"
      ],
      "id": "conservative-kelly"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "administrative-bailey"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path"
      ],
      "id": "administrative-bailey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-salem"
      },
      "source": [
        "from dataset import PatchPairsDataset, split_dataset\n",
        "from trainer import Trainer\n",
        "from evaluator import Evaluator\n",
        "from utils import show_pair, generate_submission"
      ],
      "id": "environmental-salem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loose-class"
      },
      "source": [
        "### Device"
      ],
      "id": "loose-class"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "referenced-volume"
      },
      "source": [
        "# if device is cuda, then you are using a Nvidia GPU to train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "id": "referenced-volume",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geographic-zambia"
      },
      "source": [
        "# Shows extra GPU info if there is one\n",
        "if device.type == 'cuda':\n",
        "    !nvidia-smi"
      ],
      "id": "geographic-zambia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civic-telling"
      },
      "source": [
        "### Data"
      ],
      "id": "civic-telling"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "polish-medicare"
      },
      "source": [
        "# More info about transforms: https://pytorch.org/vision/stable/transforms.html\n",
        "transform =  None \n",
        "batch_size = 16\n",
        "\n",
        "train_csv_path = \"data/train.csv\"\n",
        "test_csv_path = \"data/test.csv\"\n",
        "pairs_folder_path = \"data/patch-pairs\"\n",
        "\n",
        "train_data = PatchPairsDataset(csv_path=train_csv_path, pairs_folder_path=pairs_folder_path, transform=transform)\n",
        "\n",
        "# Split into train / val using split_dataset() from dataset.py\n",
        "train_data, val_data = split_dataset(train_data, split=0.2)\n",
        "\n",
        "test_data = PatchPairsDataset(csv_path=test_csv_path, pairs_folder_path=pairs_folder_path, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "id": "polish-medicare",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sharp-report"
      },
      "source": [
        "features, targets = iter(train_loader).next()"
      ],
      "id": "sharp-report",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "considerable-throw"
      },
      "source": [
        "features.shape"
      ],
      "id": "considerable-throw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fatal-jackson"
      },
      "source": [
        "# Show first pair\n",
        "print(f\"Target: {targets[0].item():.0f}\")\n",
        "show_pair(features[0])"
      ],
      "id": "fatal-jackson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lesser-assist"
      },
      "source": [
        "### Model"
      ],
      "id": "lesser-assist"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expressed-indonesian"
      },
      "source": [
        "#### Network architecture"
      ],
      "id": "expressed-indonesian"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "latter-earth"
      },
      "source": [
        "# Try implementing new network architectures to improve your performance!\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    \"\"\"Baseline logistic regression model\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        # Input tensor is of shape [batch_size, 6, 160, 160]\n",
        "        self.fc = nn.Linear(6 * 160 * 160, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.flatten(start_dim=1)\n",
        "        out = self.fc(x)\n",
        "        return out"
      ],
      "id": "latter-earth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automatic-baking"
      },
      "source": [
        "model = LogisticRegression()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "id": "automatic-baking",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noble-promotion"
      },
      "source": [
        "#### Loss, optimizer and scheduler"
      ],
      "id": "noble-promotion"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orange-bones"
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=3e-4)\n",
        "scheduler = None \n",
        "epochs = 10"
      ],
      "id": "orange-bones",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "determined-termination"
      },
      "source": [
        "### Saving, checkpoint and logging"
      ],
      "id": "determined-termination"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "processed-genre"
      },
      "source": [
        "# Path to which the model weights will be saved\n",
        "timestr = time.strftime(\"%m%d-%H%M\")\n",
        "save_path = f\"outputs/{timestr}\"\n",
        "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
        "save_path = os.path.join(save_path, \"\")\n",
        "# Resume training from checkpoint \n",
        "checkpoint_path = None\n",
        "# Log to tensorboard\n",
        "writer = SummaryWriter()"
      ],
      "id": "processed-genre",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reduced-comment"
      },
      "source": [
        "#### TensorBoard within notebook \n",
        "It is possible to directly display a TensorBoard window within a notebook (instead of a separate browser tab). This is especially useful when using Colab."
      ],
      "id": "reduced-comment"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swiss-country"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "id": "swiss-country",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "actual-springer"
      },
      "source": [
        "# If a timed out message is displayed, wait a bit and run this cell again.\n",
        "%tensorboard --logdir runs"
      ],
      "id": "actual-springer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "right-extra"
      },
      "source": [
        "### Training"
      ],
      "id": "right-extra"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "above-hindu"
      },
      "source": [
        "# Launch training\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        epochs=epochs,\n",
        "        device=device,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        scheduler=scheduler,\n",
        "        writer=writer,\n",
        "        save_path=save_path,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        show_pbar=True\n",
        "    )"
      ],
      "id": "above-hindu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "incredible-chain"
      },
      "source": [
        "trainer.train()"
      ],
      "id": "incredible-chain",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noble-prague"
      },
      "source": [
        "### Evaluation"
      ],
      "id": "noble-prague"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infrared-postage"
      },
      "source": [
        "# Path to the model that needs to be evaluated (can be None to use current model)\n",
        "eval_checkpoint_path = None\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    loader=test_loader,\n",
        "    checkpoint_path=eval_checkpoint_path\n",
        "    )"
      ],
      "id": "infrared-postage",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coral-reconstruction"
      },
      "source": [
        "# If the data in evaluator has targets (e.g. train or val set), you can get the accuracy using evaluate()\n",
        "print(test_loader.dataset.has_target)"
      ],
      "id": "coral-reconstruction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naval-bottom"
      },
      "source": [
        "# Use predict() to get predictions (make sure the dataloader doesn't shuffle data)\n",
        "predictions = evaluator.predict(threshold=0.5)"
      ],
      "id": "naval-bottom",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "headed-actress"
      },
      "source": [
        "### Generating a submission file"
      ],
      "id": "headed-actress"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "labeled-dietary"
      },
      "source": [
        "# Use generate_submission() to get a correctly formatted CSV\n",
        "submission_path = \"outputs/submission.csv\"\n",
        "generate_submission(predictions, submission_path)"
      ],
      "id": "labeled-dietary",
      "execution_count": null,
      "outputs": []
    }
  ]
}